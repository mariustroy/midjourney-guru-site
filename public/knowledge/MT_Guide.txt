MIDJOURNEY FOR CREATIVES
A guide by Marius Troy

Congratulations on your purchase of Imagine: Midjourney for Creatives - you're taking the first step towards unlocking Midjourney’s limitless potential!

With this guide, you'll discover the mind bending capabilities of Midjourney and how it can inspire you to new heights of creativity - whether you are looking to generate ideas, create mood boards, fuse photography with AI, or just simply create stunning art. 

Remember - Midjourney is a tool that can take your ideas to the next level, but it's up to you to provide the spark of creativity that makes your work truly outstanding. Don't settle for the ordinary - with Midjourney, you have the power to create extraordinary works of art that will leave a lasting impression on your audience.

And the best part? This guide is designed to be simple and actionable, so you can get started on your creative journey right away. With easy-to-follow instructions and practical tips, you'll be well on your way to creating images that capture your unique vision.

So let your creativity soar, and let Imagine: Midjourney for Creatives be your guide on this exciting new journey. Thanks again for your purchase - I can't wait to see what you create!

Getting Started With Midjourney
Getting started with Midjourney can seem like a daunting task, but if complete these simple steps you’ll be through the door in no time. Here’s how to get started: Go to Midjourney.com and click SIgn Up.
- Now you can either up using your either your Google or Discord account.
- If you are using DIscord you can log straight into Midjourney’s Discord server either through your browser or the Discord App (Desktop or Mobile), navigate to one 
of the #Newbie-rooms channels. Until you sign up for a paid subscription this is where you will interact with Midjourney. These open channels seem like motorways packed with traffic, and they can be pretty off-putting at first. However, one of the positive aspects of 
these open channels is that you get to watch and learn how others are writing prompts and using Midjourney to their benefit. That said, once you have a subscription you will have your own dedicated Midjourney Bot to interact with in private, and that is a calmer 
interface to interact with.
- Now that you’re in, take a minute to read the quick start guide where you’ll learn the basics of using Midjourney. You will need to understand the basics in order to get the most out of this guide.

Recently Midjourney has launched its very own web interface which in my opinion provides a much better and more extensive user experience than working through Discord. More on the Midjourney interface later.

Useful Links
Midjourney.com →
Subscription Plans →
Getting Started with Midjourney →


What are Prompts and How are they Structured
Your prompt can be just a single word, a simple phrase, or even an emoji, but in our case we need a bit more meat to the bone in order to generate realistic imagery. Here is the structure of the prompts we will use: As you can see, our prompts generally consist of three parts: 
(1) one or more reference images, (2) a text description of what to imagine, and (3) 
parameters. Parameters are basically options or settings, if you like. More on parameters later.

A prompt is a text phrase that the Midjourney Bot interprets to produce images. Once a prompt is sent, your words and phrases are broken down into smaller pieces, called Tokens that make out the building blocks of the images generated.

Adjusting your settings
Before we get started with creating images we need to ensure we’ve selected the correct Midjourney settings. For our work there really are just one tweak we need to make, but I 
do recommend reading Midjourney’s Settings Guide so that you have a thorough understanding of the different options.




Setting the Scene
In most cases text prompts include these fundamental building blocks:
- Type (Photograph, Painting, 3D Render, etc)
- Subject (The focus or main character of the prompt)
- Acting (A verb, what is the subject doing, feeling etc)
	When it comes to emotions you could be more general and write happy or sad, or 
you could choose to be more specific and write smiling or crying.  
- Style (What are the physical attributes of the subject)
	How much room for creativity to leave Midjourney with is up to you, but in regards 
to fashion you can refer to certain epochs, styles, films and even ask Midjourney to 
mix styles. Sometimes you have something very specific you’d like the subject to 
wear and that’s where reference images come to our rescue. 
- Time of day 
	Self explanatory, but this information is sometimes also used to 
get the type of light that we’re after.
- Place/Environment 
Where the photo is taken, the scenery, location or environment.



Before we start generating images, we need a basic understanding of the text prompt. The text prompt is used to create the scene we would like the Midjourney Bot to imagine. If we have something very specific in mind, it’s obviously important that we are very specific in our description of this scene. For the best results, stay precise and be economical with your words.

Each text prompt include what I call building blocks. These blocks are used to build a scene. 


Here are som examples of effective prompts. Watch the building blocks (Type, Subject, Time of day, Place, Style, Action) become an image:

Prompt example:
"Photograph of a wooden modernist house with linen draper hanging out of the window in the wind"

This image was generated using just the prompt above. One could experiment 
removing prepositions, but I have found that Midjourney is sometimes more precise when I use them.

Prompt example:
"Photograph of a wooden modernist house covered by linen drapes on the French Riviera at dusk."

Notice how Midjourney reacts to the slight changes in wording the text prompt.

Prompt example:
"Architectural photograph of a wooden modernist house covered by blue linen drapes on the French Riviera at dusk."

Prompt example:
"35mm photograph of a woman holding a camera wearing a white dress inspired by the 70s on the French Riviera in the afternoon"

Prompt example:
"70s photograph of a man wearing a suit looking out over tokyo from the top of a skyscraper in the morning."

Prompt example:
"A manga style illustration of a man wearing a suit looking out over tokyo from the top of a skyscraper in the morning."

Notice how I’ve directed MIdjourney by setting the type (illustration) of output and the style (manga) of that type. In my experience Midjourney is quite good at recognizing references to type of creative work and the different terminology and styles of major creative disciplines. 

Prompt example:
"An impressionist painting of a woman wearing a white dress under the night sky."

Again, notice how my description of type of medium and style affected the 
output. 

Prompt example:
"Blue illuminated glass sculptures on a swiss mountain at sunset during winter."

Anything is possible with great text prompts, but so far we’re only scratching 
the surface of Midjourney’s capabilities....

Understanding Midjourney’s Quirks
Before we fully embark on our journey with this AI tool, it is probably helpful to address some of Midjourney’s quirks head on.

It is important to remember that you are interacting with a machine, and the machine will at times misinterpret your words and ideas. 

Three mighty rules for interacting with the Midjourney Bot:
Try to be as precise as humanly possible. No unnecessary words in your prompts.
Stay open minded. Midjourney might not deliver exactly what you envisioned on first try, but it might hand you something unexpectedly great. You must be comfortable with handing some of the control over to the Midjourney Bot.
Try again. Adjust your test, change your reference image or settings/version, and then try again.

Photography in Midjourney
If you are looking to generate photo realistic images it helps having some basic knowledge of photography settings & equipment as -much like real photography- a Midjourney generated photograph is a result of the equipment it was ‘captured on’.

Being very specific about how a scene was captured can help produce the type of realism and/or style you are after.

There are multiple tools we can utilise to generate realistic photographs, however, I will focus on these specific tools: film stock, the lens, aperture, lighting & angle/position.

Film Stocks
An effective tool is telling Midjourney what film stock you’d like the image to be shot on. It will not necessarily render film-like images, but it will let the Midjourney Bot know that this is a photograph, and it might tilt your images towards a style you like. Here are some great 35mm films that are frequently used in film photography:

Color films
Fujifilm Fujicolor
Kodak Portra
Kodak Gold/Ultramax
Kodak Ektar
Fujifilm Pro160C
Fujifilm Superia
Cinestill 800t

Black & White Films
Ilford HP5
Ilford Delta 3200
Ilford XP2
Kodak Tri-X
Lomo Berlin Kino

There are obviously a lot of different film stocks out there, so do your own research to find the look you are after. 

Btw!
If you are using reference images in your prompts, they will (usually) interfere with 
your equipment settings, so make sure you use images that don’t contradict your 
settings/desired outcome too much if you are very particular about what you want.

The Lens
We need to let the Midjourney Bot know what lens the photo was shot with. You could actually mention the specific lens, as Midjourney does seem to have extensive knowledge of a wide range of different lenses. However, I have found that it’s usually enough to just specify the focal length. 

For those that are new to photography a lower number such as 12mm to 18mm have a wider angle of view and show more of a scene (good for landscapes, architecture, etc), while a higher number, anything from 50mm to 85mm, have a narrower angle of view and would be a great fit for something like portraits where only the subject should be in frame. 

Here are some recommended lenses:
8mm Fisheye
10-16mm Ultra wide
16-24mm Wide Angle
35-50mm Standard
55-135mm Portrait
135-300mm+ Telephoto

Macro lenses for close-up shots can range from 35mm to 200mm. If you want 
to render close-up shots of a subject this should be specified in the text prompt.

Using more general terms like ‘fisheye lens’, ‘wide angle lens’, ‘Vintage lens’, ‘Pinhole lens’ 
also seem to work as an alternative to using specific focal length. 

Aperture
Aperture affects the depth of field: larger openings create a shallower depth of field, 
while smaller openings make more of the image in focus. However the numbers are a bit 
counterintuitive, because the larger the number, the smaller the opening.

For example, f/2.8 allows twice as much light into the camera as f4, and 16 times as much light as f11. You don’t really need to understand the technicalities of this.

Aperture Settings
f/1.8 (Portraits, Low Light, Shallow Depth of Field)
f/2.8 (Portraits, Low Light, Shallow Depth of Field)
f/4 (Mid-day, Some background blurring)
f/5.6 (Mid-day, Some background blurring)
f/8 (Versatile, Almost entire image in focus)
f/12 (Landscapes, Daytime, Entire image in focus)
f/16 (Landscapes, Daytime, Entire image in focus)

Combining aperture with the right type of lens makes it easier to get the results you’re after.
Lighting - Using time of day

For anyone working in photography, this is really a crucial part of stylizing your images. 
Midjourney offers endless opportunities when it comes to lighting, but you might want dumb down your terminology a bit and be creative in how you make the Midjourney Bot do what you want it to do. 

Personally, I am a sucker for natural lighting, but there are different types of natural light, so specifying time of day or weather usually helps me get the results I’m after. I have found that it’s not necessary to mention reflectors as Midjourney does a great job lighting shadows. If you’d like more contrast you can of course specify darker shadows.

Lighting suggestions FOR MIDJOURNEY
Golden Hour (Beautiful Afternoon Light)
Dusk (Right after the sunset, before it gets dark)
Mid-day (Strong light from above)
Dawn (Fresh morning light)
Overcast afternoon (Calm lighting)
Dark Misty Light
Dark Misty
Golden Hour
Mid-day
Before Dawn

Midjourney adds additional light to make sure there’s enough light in the model’s 
face. Experiment with your wording to get the results you want.

Artificial Light
The subject of professional studio lighting is so vast that professional photographers spend years studying it before they feel that they have mastered it. I won’t elaborate on the different lighting techniques that exist, but I can say that I have found that Midjourney does understand some of the terminology, but not all.

I advise you to experiment with the wording of your settings if you’re not getting the desired results right away, and really, having great Reference Images of the type of lighting your after is a life saver here.

Also, specifying where the light is coming from is at times very useful
.
Lighting SUGGESTIONS FOR STUDIO PHOTOGRAPHY
Rembrandt Lighting
Contrasty Lighting
Soft Lighting
Side Lighting
Coloured Lighting
Volumetric Lighting

Using simpler terms (ie. ‘Contrasty Lighting’) seem to work better than famous lighting 
techniques for now. For instance, Butterfly Lighting renders images with butterflies in them.

Composition, Framing & Angle
Achieving specific compositions isn’t always easy with Midjourney, but it’s in most cases 
possible to set the framing and angle of the camera. As with anything, you need to be 
precise with your text prompts and try your best not to confuse the machine. For example, asking for a close-up portrait of someone standing in a field, will most likely not render a close-up portrait as the word ‘standing’ will confuse the Midjourney Bot. So keep it to the bone.

TERMS FOR ANGLES & FRAMING
Portrait
Close-up
Standing
Low angle
High Angle
Full body with Feet
Shoulder height

I usually mention the angle/frame as the first piece of my text prompt: ‘close-up of woman looking into camera’.

Experimenting with different lenses might also help you get the framing you want. But 
as with anything in Midjourney; trial and error.

The Power of Reference Images
I have mentioned reference images quite a few times up until this point, and there’s a good reason for that. At times it can be difficult to direct Midjourney with just text, and this is where reference images come to the rescue.

If there is a specific lighting that you’d like in your photos, a dramatic scenery or perhaps a specific styling you’d like to include, then adding reference images that show Midjourney what you’re after can be a very powerful trick. I use it all the time.

Things you should know
Reference images can be very powerful, so they have a tendency to overshadow text 
prompts. In many cases; make sure that the reference image is as consistent with the overall look you’re going for as possible. However, the way I personally use reference images is to intentionally create tension between the text prompt and the reference images. For example, if my text prompt is “70s photograph of a surreal car on the french riviera at sunset”, and I want the car to have a certain look, I can use a reference image of something seemingly unrelated like a piece of organically shaped jewelry in order to invoke a certain style. After years of experimenting with this, I now use reference images extensively to provoke Midjourney to fill in the gaps between the text prompt and the reference images. 

You can always adjust the weight in which Midjourney considers the content of a reference image  by setting the –iw image weight parameter. 

Showing an example With and Without Reference Images
In this example I have generated images using the exact same text prompt with and without a reference image. Although the image generated without a reference image is beautiful, the location and color is much more in tune with what I was looking for in the image with Reference Image.

Expand on your ideas
I’m rarely happy with the first images generated by Midjourney when I’m exploring a new idea. I use the first few attempts to perfect the prompt, and then, if I see hints of something that’s closer to what I am looking for, in earlier version of Midjourney I used the Style Tuner a lot, and then of course always the Vary functions to pursue and perfect my concepts. On the next few pages I’ll show my process for exploration and perfecting images.
Also, it is a good idea to read about asking for more versions in Midjourney’s own guide.

Explore with the Midjourney Style Tuner (Legacy)
With the release of version 5.2 in June 2023 MIdjourney introduced the Style Tuner. It is now a Legacy feature, however it was a great tool for exploring several directions. You can still use this feature with the outdated 5.2 version. For newer versions I recommend using the –choas parameter to render multiple different directions at once.

Here is an explanation of how the Style Tuner worked in Discord using v5.2:
Using the tuner requires you to spend a significant amount of your GPU credits, I suggest fine tuning your prompt before using the feature. Once you have a prompt you’d like to use type /tune in discord and enter your prompt. 

Midjourney Bot will then ask you to confirm, select the amount of Style Directions and which mode you’d like to use. Selecting a higher amount of directions will give you more to choose from, but it will also eat away at your GPU credits. 

Unless you normally use Raw-mode, I suggest staying in Default. The Raw-mode is supposedly instructing the Midhjourney engine to be less opinionated, but most of 
the time I don’t really find there to be much of a difference. 

Once the tuner is ready you get a message from Midjourney Bot telling you the ‘Style Tuner is Ready’ with a link to a page listing the style directions. 

You can either compare two-and-two styles at a time, or pick your favorites from a large grid. I prefer the first view option as you can only see one out of the four images per 
style in the grid view.

When you select a style by clicking on a 4-image-grid or image (in grid view), the Style Tuner will generate a prompt with a unique style code at the bottom of the page. You can copy this code and paste it as your next Midjourney prompt to generate images resembling that style. You won’t get the exact same images as presented in the tuner, 
but you can clearly tell they are related.

You can also select more than one style suggestion, combining the ideas you like. I have found this to water down the aesthetics a bit, but there are definitely use cases where 
this would be valuable. 

Once you have a style code you can use this to explore other ideas with that same aesthetic, or you can share the tuner page or your unique style code(s) with others. 

The spread in visual directions is often determined by the nature of your prompt; the more specific you are with your words and reference images, the less room for aesthetic exploration for the Style Tuner. and the more generic you are the more the styles offered will differ from each other.

Using the v7 Draft mode
Draft Mode is a new speed demon in v7. It trades a bit of polish for blazing fast render times and creative spontaneity. Use it when:
	•	You’re brainstorming visual directions fast.
	•	You want raw concept over perfect polish.

To enable:
Add --style raw or choose it via /settings. It’s not about “ugly” — it’s about letting loose.

Example
Prompt with --style raw → looser brushstrokes, more abstraction, faster.
Quick tip: 
Dial it in early to explore bold shapes + composition. Switch to standard for final beauty.
Think of it as napkin sketch mode for your imagination.


Using Remix mode to better control variations
Using the Remix feature will allow you more control when exploring ideas in Midjourney. It allows you to edit your prompt for each time you generate new variations of previously generated images. 

Explore & Expand on your ideas with Vary
After generating an image Midjourney provides you with options to generate new variations of that image; Vary (Strong) and Vary (Subtle).

The Strong option is great to use when you’d like to generate a new set of different images within the same concept as the initial image. The Subtle option is great for the situations when you have an image you are quite happy with, but you would just like to change minor details

I use the vary buttons quite frequently when exploring ideas to see if Midjourney can take my ideas in new unexpected directions.

The new Edit Options
The new edit functionalities added with the latest versions of Midjourney are quite extensive and extend past just inpainting or removing objects from an image. Here are some the options available in Edit:

Erase & Restore: Brush over areas to remove elements or bring them back. Ideal for tweaking specific parts without starting over.


Scale & Zoom: Adjust the size of your image within the canvas, allowing for creative reframing or expanding the scene.


Aspect Ratio & Pan: Change the image’s dimensions or move it around to focus on different elements.


Prompt Editing: Modify your original prompt to influence the regeneration of selected areas.


Undo/Redo/Reset: Easily revert changes or start fresh if needed.


Smart Select: Automatically selects regions for editing, streamlining the process of making precise changes.


Suggest Prompt: Generates prompt suggestions based on your selected layer or image, aiding in creative exploration.


Style & Character References: Incorporate specific styles or maintain character consistency across images.


Image Retexturing: Alters the lighting, materials, and surfaces of your image, providing a fresh look while preserving the original structure.



To use the Web Editor, navigate to your image on midjourney.com, click on it, and select the “Editor” option. Note that some features may require a certain number of generated images or a specific subscription level.

Here are some examples of how I use the editor in my workflow:

Adding Objects
Sometimes an image just needs the little extra too feel complete. Vary Region is great for 
supplying generated images with that little extra. 

Removing Objects
Other times you just need to remove something from your image. 

Changing Outfit
And sometimes you need to change the outfit of a subject in your image to enhance the 
composition. In order to select the outfit I’d like to switch I used Smart Select tool mark it.

Using Zoom & Pan to paint a bigger picture
When generating images Midjourney provides two options to expand the frame with Zoom Out and the arrow buttons for Panning. These options are great ways to paint a bigger picture once you have something you like. Clicking the Custom Zoom also provides you the option adjust the zoom amount and the prompt, handing you control over what it generates when expanding the frame. Zooming out 2x is the maximum amount per time. 

The Panning feature let’s you generate images of higher resolution than the initial image, 
adding pixels rather than restricting the resolution. 

Configure the output with Parameters

The last piece of your prompt is a list of Parameters. We use parameters to configure options such as the aspect ratio of our images, exclude certain objects from our images, and what version of Midjourney we would like to use.

A full list of Midjourney’s parameters can be found on MIdjourney’s website. 

In the following text I will go through some of the most useful parameters for maximum creative control.

Aspect Ratio
--ar sets the Aspect ratio of your images, ie. ‘--ar 3:4’ sets an aspect ratio of 3:4.

USEFUL Aspect Ratios:
Instagram Post 4:5 
Instagram Stories 9:16
35mm Photographic film 2:3
Television/Presentation 16:9
Old Television 4:3

Negative Prompting 
--no excludes things from your images, ie. ‘--no balcony’ prevents Midjourney from generating images that include balconies.

Image Weight
You can use --iw to tilt the weight between a Reference Image and your text prompt. In Midjourney version 5 the --iw values range from .5 to 2, where a higher value means 
the reference images have a higher impact on the results. Default value is 1.
 
Render Quality
--quality or --q determines the time spent rendering your image, meaning you’ll get a more detailed image by setting a higher value, but you will also spend more of your GPU hours. 

You can use values between .25 and 2. 1 is default. I usually don’t use this parameter at all until I have a something I would like to spend the render time on, and render time cost money. 

I don’t recommend going below 1 for any ideas that include humans.

In version 7 the quality parameter works differently.
• On May 2, 2025 the version 7 model was optimized to use less GPU time and provide better coherence for hands (default --q 1).
• To use V7 before the optimization, add --q 2 to the end of your prompt.
• Use --q 4 for a new experimental mode that may provide better details and coherence.
• --q 4 is not compatible with Omni Reference
• If you want to use a lower quality setting, check out Draft Mode.

Chaos
--chaos or --c determines how varied your results will be when Midjourney presents its four images. Higher values will produce more varied and ‘wild’ results. A lower value is more conservative. The values range is 0 to 100, where 0 is the default value.


Stylize
--stylize or --s determine how closely the generated images will match your prompt. A low value is closer to your prompt, a higher value gives Midjourney more artistic freedom when generating images.

100 is the default value. 

Midjourney Version
--v sets the version of Midjourney. At the moment I generally use v6.1 as I feel it fits my aesthetic better than v7. 

Each version of Midjourney has its own personality, if you like, so I encourage you to alternate between v4, v5, v5.1, v5.2, v6, v6.1 and v7 to find the aesthetic you’re after.

Character Consistency
There are times where you would like to produce a series of images using the same model/character. In earlier versions of Midjourney this was not a straight forward process, however with the introduction of Character Reference in v6, and now Omni Reference in v7, it is a much simpler process.

Character Reference --cref
This feature allows you to maintain a specific character’s appearance across multiple images.
Usage: Add --cref [image URL] to your prompt.


Adjust Detail with --cw: Control how much of the character’s features are retained:


--cw 100: Preserves face, hair, and clothing.
--cw 0: Focuses primarily on facial features, allowing changes in attire or hairstyle.


Best practices: 
Use images generated by Midjourney for optimal results.
Combine with detailed text prompts to guide the scene and context.
Compatible with Midjourney and Niji version 6 models.


Omni-Reference --oref
A more versatile tool introduced in version 7, Omni-Reference lets you embed any visual element—be it a character, object, or creature—into your generated images. 
Usage: Add --oref [image URL] to your prompt. 
Control Influence with --ow: Adjust the strength of the reference:
	•	--ow 25: Light influence, suitable for style transfers.
	•	--ow 100: Balanced influence, default setting.
	•	--ow 400: Strong influence, ideal for preserving intricate details.
	•	--ow 1000: Maximum influence, closely replicates the reference.   
	
Considerations:
	•	Only one reference image per prompt.
	•	Not compatible with inpainting, outpainting, Draft Mode, or Fast Mode.
	•	Using Omni-Reference doubles the GPU time required for rendering.

Using Style Reference --sref
Midjourney’s Style Reference feature (--sref) lets you infuse your prompts with the aesthetic essence of an existing image—capturing its color palette, texture, lighting, and mood—without replicating its specific content.

Think of --sref as a style transfer tool. It extracts the visual vibe from your reference image and applies it to your new creation, ensuring stylistic consistency across different subjects. This is particularly useful for maintaining a cohesive look in a series of images. 
How to Use It
Upload Your Reference Image: If your image isn’t already online, upload it to Discord or another hosting service to obtain a URL. 
Construct Your Prompt: Use the /imagine command followed by your descriptive prompt. 
Add the Style Reference Parameter: Append --sref followed by the image URL to your prompt.
Adjust Style Influence (Optional): Use the --sw parameter to control how strongly the style is applied. The default is 100; increase up to 1000 for a stronger influence.
Combine Multiple Styles (Optional): You can reference multiple images by adding multiple URLs after --sref. Assign weights to each using double colons ::

Best Practices
Keep Prompts Content-Focused: Describe what you want to see, not how it should look. Let the style reference handle the aesthetics. 
Avoid Conflicting Style Descriptors: Adding style-related adjectives in your prompt can clash with the reference image’s style. 
Use High-Quality Reference Images: Clear, well-lit images with distinct styles yield better results.
Experiment with Style Weight: Adjust the --sw parameter to find the right balance between your prompt and the style influence.

Personalisation of Midjourney
Personalization allows you to create a custom model by teaching Midjourney your visual tastes. By ranking image pairs or curating moodboards, you guide the AI to understand and replicate your preferred styles in generated images.

How to Set It Up
Rank Image Pairs: On the Midjourney website, navigate to the “Personalize” section. You’ll be presented with pairs of images—select the one that resonates more with your style. Aim to rank at least 40 images to activate the feature, though 200+ rankings yield better results.  
Create Moodboards: Alternatively, you can upload or link images that exemplify your desired style. This method allows the AI to learn from specific visuals you provide.

Using Personalization in Prompts
Basic Usage: Add --p to your prompt to apply your personalized style.
Specify a Profile: If you have multiple personalization profiles, you can specify one using its unique code
Adjust Stylization: Control the influence of your personalization with the --stylize parameter (values range from 0 to 1000). Higher values apply more of your style preferences.

Sharing and Exploring Styles
Each personalization profile has a unique code that can be shared. By using someone else’s code with the --p parameter, you can generate images in their style.


Common pitfalls in MIdjourney
As you now know Midjourney is a cumbersome but powerful tool to work with, and although the imagery generated can at times take your breath away, there are certain things Midjourney really struggle to get right.

Here’s a short list of what to look out for:

Hands & Feet. Midjourney has a tendency to really mess up hands & 
feet. If everything looks perfect, make sure you take an extra look at 
the hands and feet before you use the image.

Noses & Eyes. Sometimes you can just sense that something is not quite right with a rendered face. Usually the nostrils or the fake looking shade in the eyes is the cause. 

Text. Midjourney generates text, but it’s always jibberish. So use negative prompting (‘--no text’) to exclude text from your generated images. There have been reports 
of people using Vary Region to fix text, but I have not been able to make it work.

Relative size. An image might look good at first glance, but pay close attention to the size of objects in relation to each other. Arms might be way too long, a chair way too 
small, etc.

Cars & other vehicles. Midjourney doesn’t seem to understand the logic of vehicles, so it might render the weirdest looking automobiles. Beware.

Buildings & Structures. When producing images of architecture or any other structure, pay attention to the fine details. Stairs and railings are common culprits.

Crowds. Even in the latest version of Midjourney it really does seem to be able to render many faces at once. 

There are obviously other things as well, but these are the aspects I have encountered the most. 

Upscaling your Midjourney Images

In earlier versions of Midjourney you could only generate images up to 1024x1024px resolution. The new versions of Midjourney lets you upscale up to around 3000px, with options Subtle Upscale (keeps the image very true to its original) and Creative Upscale (fills in more blanks and gets a bit too creative sometimes in my opinion). How does the native upscale feature compare to other AI tools that specialise in upscaling images and artwork for professional use?

In my experience, the two best premium tools for upscaling are Gigapixel AI and Photoshop. If you have Photoshop you can find its upscaler under Filter > Neural Filters 
> Super Zoom. 

And while I have been getting ok results scaling up my images in photoshop, I have always been very impressed with the result I’ve gotten in Gigapixel AI, and I still use it today, even after Midjourney released its own upscaling feature. 

The reason for this is the amount of options and controls offered by Gigapixel AI, but also because of the look and feel of the images. I have found the scaled Midjourney images to be a bit too smooth (plasticky) for my liking, while images look more 
crisp using Gigapixel AI.

Further Exploration
We have now covered the tools and workflows needed to produce striking imagery. However, there are a few valuable features in Midjourney that we have not touched on, that still deserve the mention:

The /describe Command
This command is a great a tool to help you understand how the Midjourney Bot thinks and explore its vocabulary. The /describe command allows you to upload an image and generate four possible prompts based on how Midjourney sees that image.


You have reached the end!
Congratulations on completing this guide! Hopefully, you’re now able to extract the powers of Midjourney to fuel your creativity. 

If you feel that something is missing from this guide, have a request for additions or corrections, or just general feedback, feel free to reach out on Instagram or by email at c@maisontroy.com.
